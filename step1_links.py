# -*- coding: utf-8 -*-
"""
STEP 1: ì „ë‚  í•˜ë£¨ì¹˜ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼(ì œëª©/ë§í¬) ìˆ˜ì§‘

- ëŒ€ìƒ: KEYWORDS ë¦¬ìŠ¤íŠ¸ì˜ (ê²€ìƒ‰ì¿¼ë¦¬, í–‰ì •ë™ëª…)
- ë‚ ì§œ: ì˜¤ëŠ˜ ê¸°ì¤€ 'ì „ë‚ ' í•˜ë£¨
- ì €ì¥ ìœ„ì¹˜:
    ./data_html/{ë™ë„¤}_ëª…ì†Œ/{YYYY}/links/links_{ë™ë„¤}_ëª…ì†Œ_{YYYYMMDD}.csv
"""

import os
import re
import time
import random
import pandas as pd
from datetime import datetime, timedelta
from urllib.parse import quote

from seleniumwire import webdriver
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait

# =========================
# ğŸ” ìˆ˜ì§‘í•  KEYWORDS
# =========================
KEYWORDS = [
    ("ì„±ìˆ˜ë™ ëª…ì†Œ", "ì„±ìˆ˜ë™"),
    ("ì—°ë‚¨ë™ ëª…ì†Œ", "ì—°ë‚¨ë™"),
    ("ìµì„ ë™ ëª…ì†Œ", "ìµì„ ë™"),
    ("ì„ì§€ë¡œ ëª…ì†Œ", "ì„ì§€ë¡œ"),
    ("ì‹ ì‚¬ë™ ëª…ì†Œ", "ì‹ ì‚¬ë™"),
    ("ê³µë¦‰ë™ ëª…ì†Œ", "ê³µë¦‰ë™"),
    ("í•œë‚¨ë™ ëª…ì†Œ", "í•œë‚¨ë™"),
]

WAIT_SEC     = 25
PAUSE        = (0.8, 1.6)
SCROLL_STEPS = 4

def human_pause(a=1.0, b=2.0):
    time.sleep(random.uniform(a, b))

def clean(s):
    return re.sub(r"\s+", " ", (s or "").strip())

def sanitize_for_fname(s: str) -> str:
    s = s.strip().replace(" ", "_")
    s = re.sub(r"[^\w\-\.ê°€-í£]+", "", s)
    return s

# -------------------------
# ğŸ”§ Driver ìƒì„±
# -------------------------
def build_driver():
    opts = uc.ChromeOptions()
    opts.add_argument("--lang=ko-KR")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--window-size=1400,900")
    opts.add_argument("--disable-blink-features=AutomationControlled")
    opts.add_argument(
        "user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0.0.0 Safari/537.36"
    )
    return webdriver.Chrome(
        options=opts,
        seleniumwire_options={"verify_ssl": True, "disable_encoding": True},
    )

# -------------------------
# ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ URL ìƒì„± (í•˜ë£¨ ë‹¨ìœ„, ë¸”ë¡œê·¸ íƒ­ ê°•ì œ)
#  - ë„¤ê°€ ì§ì ‘ í™•ì¸í•œ íŒ¨í„´:
#    https://search.naver.com/search.naver?ssc=tab.blog.all&sm=tab_jum&query=ì„±ìˆ˜ë™+ëª…ì†Œ
#  - ì—¬ê¸°ì— nso(ë‚ ì§œ)ë§Œ ë¶™ì—¬ì„œ ì‚¬ìš©
# -------------------------
def build_search_url(q, day):
    f = day.strftime("%Y%m%d")
    # nsoëŠ” ì›ë˜ì²˜ëŸ¼ so:dd,p:fromYYYYMMDDtoYYYYMMDD
    nso = f"so:dd,p:from{f}to{f}"

    return (
        "https://search.naver.com/search.naver"
        "?ssc=tab.blog.all"
        "&sm=tab_jum"
        f"&query={quote(q)}"
        f"&nso={nso}"
    )

# -------------------------
# ğŸ“Œ Debug ì €ì¥
# -------------------------
def dump_debug(driver, label, save_dir):
    os.makedirs(save_dir, exist_ok=True)
    html_path = os.path.join(save_dir, f"DEBUG_{label}.html")
    png_path  = os.path.join(save_dir, f"DEBUG_{label}.png")
    try:
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
    except Exception:
        pass
    try:
        driver.save_screenshot(png_path)
    except Exception:
        pass
    print(f"   â†³ ë””ë²„ê·¸ ì €ì¥: {html_path}, {png_path}")

# -------------------------
# CSS ì…€ë ‰í„° í›„ë³´êµ° (ë¸”ë¡œê·¸ ê²°ê³¼ìš©)
# -------------------------
TITLE_SELECTORS = [
    "a.api_txt_lines.total_tit",   # ì˜ˆì „/í˜„ì¬ ë¸”ë¡œê·¸ ì œëª© ë§í¬
    "a.total_tit",
    "a.title_link",
    "div.total_wrap a[href*='blog.naver.com']",
    "a[href*='blog.naver.com']",
]

def ensure_results_ready(driver):
    try:
        # í˜ì´ì§€ ì „ì²´ ë¡œë”© ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë¦¬ê¸°
        WebDriverWait(driver, WAIT_SEC).until(
            lambda d: d.execute_script("return document.readyState") == "complete"
        )

        # lazy load ìœ ë„(ìŠ¤í¬ë¡¤ ìœ„ì•„ë˜ ì¡°ê¸ˆì”©)
        for _ in range(2):
            driver.execute_script("window.scrollBy(0, document.body.scrollHeight*0.5);")
            time.sleep(0.8)
            driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(0.4)

        # ë¸”ë¡œê·¸ ê²°ê³¼ ì˜ì—­ì´ ì‹¤ì œë¡œ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        def ok(d):
            for s in TITLE_SELECTORS:
                if d.find_elements(By.CSS_SELECTOR, s):
                    return True
            # ë¸”ë¡œê·¸ ê²°ê³¼ê°€ ì•„ì˜ˆ ì—†ì„ ë•Œë„ ë¹ ì ¸ë‚˜ì˜¤ë„ë¡
            return "ê²€ìƒ‰ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤" in d.page_source

        WebDriverWait(driver, WAIT_SEC).until(ok)
        return True
    except Exception:
        return False

def click_next(driver):
    # ë¸”ë¡œê·¸ ê²€ìƒ‰ í˜ì´ì§€ì˜ "ë‹¤ìŒ" ë²„íŠ¼ë“¤ í›„ë³´
    for sel in ["a.btn_next", "a.pg_next", "a.sc_page_next", "a[aria-label='ë‹¤ìŒ']"]:
        btns = driver.find_elements(By.CSS_SELECTOR, sel)
        if btns and btns[0].is_displayed():
            try:
                btns[0].click()
                return True
            except Exception:
                pass
    return False

# -------------------------
# ğŸ” í•˜ë£¨ì¹˜ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
# -------------------------
def list_seeds_for_day(driver, query, day, save_dir, dong_slug):
    url = build_search_url(query, day)
    print(f"\nğŸ“… [{dong_slug}] {day:%Y-%m-%d} ë§í¬ ìˆ˜ì§‘ ì‹œì‘: {url}")

    driver.get(url)

    # ì‹¤ì œë¡œ ì–´ë””ë¡œ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸ (í†µí•©ì¸ì§€ / ë¸”ë¡œê·¸ì¸ì§€ ì²´í¬ìš©)
    print("   ğŸ‘‰ ì‹¤ì œ ì ‘ì†ëœ URL:", driver.current_url)

    if not ensure_results_ready(driver):
        print("âš ï¸ ì´ˆê¸° ë¡œë”© ì‹¤íŒ¨")
        dump_debug(driver, f"{dong_slug}_{day:%Y%m%d}_init_fail", save_dir)
        return []

    seeds, seen = [], set()
    page_idx = 1

    while True:
        # ìŠ¤í¬ë¡¤ â†’ lazy load
        for _ in range(SCROLL_STEPS):
            driver.execute_script("window.scrollBy(0, document.body.scrollHeight*0.85);")
            human_pause(*PAUSE)

        anchors = []
        for sel in TITLE_SELECTORS:
            anchors = driver.find_elements(By.CSS_SELECTOR, sel)
            if anchors:
                break

        if not anchors:
            print(f"âš ï¸ [{dong_slug}] p{page_idx} ì œëª© ì…€ë ‰í„° ì—†ìŒ")
            dump_debug(driver, f"{dong_slug}_{day:%Y%m%d}_p{page_idx}_no_titles", save_dir)

        for a in anchors:
            href = a.get_attribute("href") or ""
            if not href:
                continue
            if ("blog.naver.com" not in href) and ("m.blog.naver.com" not in href):
                continue
            if href in seen:
                continue

            seen.add(href)
            title = clean(a.text) or clean(a.get_attribute("title") or "")
            seeds.append(
                {
                    "date": day.strftime("%Y-%m-%d"),
                    "title": title,
                    "link": href,
                }
            )

        if not click_next(driver):
            break
        page_idx += 1
        human_pause(*PAUSE)

    print(f"ğŸ”— [{dong_slug}] ìˆ˜ì§‘ ë§í¬: {len(seeds)}ê±´")
    return seeds

# -------------------------
# ğŸ’¾ í•˜ë£¨ì¹˜ CSV ì €ì¥
# -------------------------
def save_csv(rows, dong_slug, day, save_dir):
    if not rows:
        print(f"ğŸ“¦ [{dong_slug}] {day:%Y%m%d}: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
        return

    df = pd.DataFrame(rows, columns=["date", "title", "link"])
    df = df.drop_duplicates(subset=["link"]).reset_index(drop=True)

    os.makedirs(save_dir, exist_ok=True)
    out_path = os.path.join(save_dir, f"links_{dong_slug}_{day:%Y%m%d}.csv")
    df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"âœ… [{dong_slug}] CSV ì €ì¥ ì™„ë£Œ â†’ {out_path}")

# -------------------------
# ğŸš€ PUBLIC API: ì „ë‚  í•˜ë£¨ì¹˜ ì „ì²´ KEYWORDS ì‹¤í–‰
# -------------------------
def run_step1(target_day=None):
    """
    target_dayê°€ Noneì´ë©´ 'ì˜¤ëŠ˜ ê¸°ì¤€ ì „ë‚ 'ë¡œ ì„¤ì •.
    """
    if target_day is None:
        today = datetime.now()
        target_day = today - timedelta(days=1)

    driver = build_driver()
    try:
        for query, dong in KEYWORDS:
            dong_slug = f"{dong}_ëª…ì†Œ"
            year_str = target_day.strftime("%Y")
            save_dir = f"./data_html/{dong_slug}/{year_str}/links"

            rows = list_seeds_for_day(
                driver=driver,
                query=query,
                day=target_day,
                save_dir=save_dir,
                dong_slug=dong_slug,
            )
            save_csv(rows, dong_slug, target_day, save_dir)
    finally:
        driver.quit()

# -------------------------
# ğŸ§ª ì§ì ‘ ì‹¤í–‰ìš©
# -------------------------
def main():
    run_step1()

if __name__ == "__main__":
    main()
